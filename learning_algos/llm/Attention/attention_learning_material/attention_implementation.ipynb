{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attension is all you need - Coding attention layer\n",
    "\n",
    "In this notebook I will be coding the attention layer from basics <br>\n",
    "\n",
    "Following is the attention equation which is the \"bhramastra of LLMs -\" <br>\n",
    "\n",
    "\n",
    " <center> <img src=\"./images/attention_euqation.png\" alt=\"Drawing\" style=\"width: 200px;\"/> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data (text) from attention is all you need paper\n",
    "link - https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in /Users/raghavsharma/anaconda3/envs/learn_llm/lib/python3.13/site-packages (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/raghavsharma/anaconda3/envs/learn_llm/lib/python3.13/site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/raghavsharma/anaconda3/envs/learn_llm/lib/python3.13/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/raghavsharma/anaconda3/envs/learn_llm/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/raghavsharma/anaconda3/envs/learn_llm/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/raghavsharma/anaconda3/envs/learn_llm/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/raghavsharma/anaconda3/envs/learn_llm/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "# !pip install beautifulsoup4\n",
    "# !pip install requests\n",
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Domain\n",
      "Example Domain\n",
      "This domain is for use in illustrative examples in documents. You may use this\n",
      "    domain in literature without prior coordination or asking for permission.\n",
      "More information...\n"
     ]
    }
   ],
   "source": [
    "from utils import get_website_text\n",
    "\n",
    "url = \"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\"\n",
    "text_content = get_website_text(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_string(s):\n",
    "    \"\"\"\n",
    "    Removes characters from the string `s` that are not letters, digits, spaces, or exclamation marks.\n",
    "    \n",
    "    Args:\n",
    "        s (str): Input string.\n",
    "\n",
    "    Returns:\n",
    "        str: Cleaned string with only allowed characters.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^A-Za-z0-9 !]', '', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_content  = clean_string(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding(\"o200k_base\") \n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "# To get the tokeniser corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = enc.encode(text_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(set(text_content))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88355\n"
     ]
    }
   ],
   "source": [
    "n  = int(0.9*len(data))\n",
    "print(n)\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "embed = nn.Embedding(vocab_size,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_window  = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98165"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data) - context_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([64228, 85292, 85781, 19426])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(len(data) - context_window, (batch_size, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert data points into B,T,C B- batch size T-block size (time dimension) C - embed size  (character dimenrsion)\n",
    "\n",
    "#getting the batches \n",
    "\n",
    "def get_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
