{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghavsharma/anaconda3/envs/learn_llm/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n",
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Error while downloading from https://cdn-lfs-us-1.hf.co/repos/4a/a7/4aa7b074fda985a41c347453e29e295a88918e98691e0f71da924481ca5e50d8/b7492726c01287bf6e13c3d74c65ade3d436d50da1cf5bb6925bc962419d6610?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1749408460&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0OTQwODQ2MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzRhL2E3LzRhYTdiMDc0ZmRhOTg1YTQxYzM0NzQ1M2UyOWUyOTVhODg5MThlOTg2OTFlMGY3MWRhOTI0NDgxY2E1ZTUwZDgvYjc0OTI3MjZjMDEyODdiZjZlMTNjM2Q3NGM2NWFkZTNkNDM2ZDUwZGExY2Y1YmI2OTI1YmM5NjI0MTlkNjYxMD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=avqeDhKGzXe6rvc1cmK4nI-0YuKTXOO04gvLR8UhXkVEJ1zFBia8IVbFCdXGa-ownkWBzoYV-DDB1otMC-hq4htpo4tyxx9pud4VB-XDR6w5Z8dJlxWebufQZr2GzPVyaAXv7yykDQm%7ELHh4PHZA9sAABhWDYtRnd0o3%7EsEHbSFfXGlXrlzjtUh6CbFieyuXj1mEJPlpJqLJZ7CWBZi300txtw%7EOodgRCzZCt0dkgD1XcgA1j1KZZwEZEkWt5WS-Du%7EwsggvqQVEpPZpgz-mqLKzzlPNh9e2MAlaI9Kyq9X0A-JQfDVGAJYENsDe-Yq7vY%7ERaT6fn4xEl9L8aUKZ0w__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Fetching 2 files: 100%|██████████| 2/2 [1:14:30<00:00, 2235.14s/it]  \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:27<00:00, 13.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", device_map = \"cuda\", \n",
    "                            trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"microsoft/Phi-3-mini-4k-instruct\", \n",
    "                        trust_remote_code=True, \n",
    "                                tokenizer = tokenizer, \n",
    "                                return_full_text = False, \n",
    "                                max_new_tokens  = 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \"content\": \"What do you know about physics laws.\"\n",
    "}]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
